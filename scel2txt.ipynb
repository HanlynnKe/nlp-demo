{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "import os\n",
    "\n",
    "# 由于原代码不适用python3且有大量bug\n",
    "# 以及有函数没有必要使用且一些代码书写不太规范或冗余\n",
    "#在原有的大框架基本不动的情况下作了大量的细节更改。\n",
    "# 使得没有乱码出现，文件夹导入更方便等等。\n",
    "\n",
    "\n",
    "# 原作者：\n",
    "# 搜狗的scel词库就是保存的文本的unicode编码，每两个字节一个字符（中文汉字或者英文字母）\n",
    "# 找出其每部分的偏移位置即可\n",
    "# 主要两部分\n",
    "# 1.全局拼音表，貌似是所有的拼音组合，字典序\n",
    "#       格式为(index,len,pinyin)的列表\n",
    "#       index: 两个字节的整数 代表这个拼音的索引\n",
    "#       len: 两个字节的整数 拼音的字节长度\n",
    "#       pinyin: 当前的拼音，每个字符两个字节，总长len\n",
    "#\n",
    "# 2.汉语词组表\n",
    "#       格式为(same,py_table_len,py_table,{word_len,word,ext_len,ext})的一个列表\n",
    "#       same: 两个字节 整数 同音词数量\n",
    "#       py_table_len:  两个字节 整数\n",
    "#       py_table: 整数列表，每个整数两个字节,每个整数代表一个拼音的索引\n",
    "#\n",
    "#       word_len:两个字节 整数 代表中文词组字节数长度\n",
    "#       word: 中文词组,每个中文汉字两个字节，总长度word_len\n",
    "#       ext_len: 两个字节 整数 代表扩展信息的长度，好像都是10\n",
    "#       ext: 扩展信息 前两个字节是一个整数(不知道是不是词频) 后八个字节全是0\n",
    "#\n",
    "#      {word_len,word,ext_len,ext} 一共重复same次 同音词 相同拼音表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拼音表偏移，\n",
    "startPy = 0x1540\n",
    "\n",
    "# 汉语词组表偏移\n",
    "startChinese = 0x2628\n",
    "\n",
    "# 全局拼音表\n",
    "GPy_Table = {}\n",
    "\n",
    "# 解析结果\n",
    "# 元组(词频,拼音,中文词组)的列表\n",
    "GTable = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 原始字节码转为字符串\n",
    "def byte2str(data):\n",
    "    pos = 0\n",
    "    str = ''\n",
    "    while pos < len(data):\n",
    "        c = chr(struct.unpack('H', bytes([data[pos], data[pos + 1]]))[0])\n",
    "        if c != chr(0):\n",
    "            str += c\n",
    "        pos += 2\n",
    "    return str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取拼音表\n",
    "def getPyTable(data):\n",
    "    data = data[4:]\n",
    "    pos = 0\n",
    "    while pos < len(data):\n",
    "        index = struct.unpack('H', bytes([data[pos],data[pos + 1]]))[0]\n",
    "        pos += 2\n",
    "        lenPy = struct.unpack('H', bytes([data[pos], data[pos + 1]]))[0]\n",
    "        pos += 2\n",
    "        py = byte2str(data[pos:pos + lenPy])\n",
    "\n",
    "        GPy_Table[index] = py\n",
    "        pos += lenPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取一个词组的拼音\n",
    "def getWordPy(data):\n",
    "    pos = 0\n",
    "    ret = ''\n",
    "    while pos < len(data):\n",
    "        index = struct.unpack('H', bytes([data[pos], data[pos + 1]]))[0]\n",
    "        ret += GPy_Table[index]\n",
    "        pos += 2\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取中文表\n",
    "def getChinese(data):\n",
    "    pos = 0\n",
    "    while pos < len(data):\n",
    "        # 同音词数量\n",
    "        same = struct.unpack('H', bytes([data[pos], data[pos + 1]]))[0]\n",
    "\n",
    "        # 拼音索引表长度\n",
    "        pos += 2\n",
    "        py_table_len = struct.unpack('H', bytes([data[pos], data[pos + 1]]))[0]\n",
    "\n",
    "        # 拼音索引表\n",
    "        pos += 2\n",
    "        py = getWordPy(data[pos: pos + py_table_len])\n",
    "\n",
    "        # 中文词组\n",
    "        pos += py_table_len\n",
    "        for i in range(same):\n",
    "            # 中文词组长度\n",
    "            c_len = struct.unpack('H', bytes([data[pos], data[pos + 1]]))[0]\n",
    "            # 中文词组\n",
    "            pos += 2\n",
    "            word = byte2str(data[pos: pos + c_len])\n",
    "            # 扩展数据长度\n",
    "            pos += c_len\n",
    "            ext_len = struct.unpack('H', bytes([data[pos], data[pos + 1]]))[0]\n",
    "            # 词频\n",
    "            pos += 2\n",
    "            count = struct.unpack('H', bytes([data[pos], data[pos + 1]]))[0]\n",
    "\n",
    "            # 保存\n",
    "            GTable.append((count, py, word))\n",
    "\n",
    "            # 到下个词的偏移位置\n",
    "            pos += ext_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scel2txt(in_path,file_name):\n",
    "    print('-' * 60)\n",
    "    with open(in_path+file_name, 'rb') as f:\n",
    "        data = f.read()\n",
    "\n",
    "    print(\"词库名：\", byte2str(data[0x130:0x338])) # .encode('GB18030')\n",
    "    print(\"词库类型：\", byte2str(data[0x338:0x540]))\n",
    "    print(\"描述信息：\", byte2str(data[0x540:0xd40]))\n",
    "    print(\"词库示例：\", byte2str(data[0xd40:startPy]))\n",
    "\n",
    "    getPyTable(data[startPy:startChinese])\n",
    "    getChinese(data[startChinese:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    # scel所在文件夹路径\n",
    "    in_path = u\"/\"\n",
    "\n",
    "\n",
    "    # 输出词典所在文件夹路径\n",
    "    out_path = u\"/my_dict.txt\"\n",
    "\n",
    "    fin = [fname for fname in os.listdir(in_path) if fname[-5:] == \".scel\"]\n",
    "\n",
    "\n",
    "    # print(fin)\n",
    "    for f in fin:\n",
    "        scel2txt(in_path,f)\n",
    "\n",
    "    # 保存结果\n",
    "    with open(out_path, 'w', encoding='utf8') as f:\n",
    "        f.writelines([word+'\\n' for count, py, word in GTable])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
